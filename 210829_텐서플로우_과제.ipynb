{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled2.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyN8FzmIsrokGE8MHu9gJjYz",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ParkSunhwa/200722_BootCamp1/blob/master/210829_%ED%85%90%EC%84%9C%ED%94%8C%EB%A1%9C%EC%9A%B0_%EA%B3%BC%EC%A0%9C.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3aBSgtZytW5G"
      },
      "source": [
        "# 필요한 모듈 임포트 \n",
        "import numpy as np\n",
        "import os\n",
        "import tensorflow as tf\n",
        "import tensorflow.keras\n",
        "\n",
        "from tensorflow.keras.datasets import cifar10\n",
        "from tensorflow.keras.models  import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D\n",
        "from tensorflow.keras.regularizers import l2\n",
        "import matplotlib.pyplot as plt\n",
        "from pylab import rcParams\n",
        "rcParams['figure.figsize'] = 5, 5\n",
        "\n",
        "# cifar10 이미지 로딩\n",
        "(X_train, y_train), (X_test, y_test) = cifar10.load_data()\n",
        "\n",
        "print (\"Training data:\")\n",
        "print (\"Number of examples: \", X_train.shape[0])\n",
        "print (\"Number of channels:\",X_train.shape[3]) \n",
        "print (\"Image size:\", X_train.shape[1], X_train.shape[2])\n",
        "print\n",
        "print (\"Test data:\")\n",
        "print (\"Number of examples:\", X_test.shape[0])\n",
        "print (\"Number of channels:\", X_test.shape[3])\n",
        "print (\"Image size:\", X_test.shape[1], X_test.shape[2]) \n",
        "\n",
        "print(X_train.shape, X_train.dtype)\n",
        "\n",
        "# 이미지 시각화\n",
        "plt.subplot(141)\n",
        "plt.imshow(X_train[0], interpolation=\"bicubic\")\n",
        "plt.grid(False)\n",
        "plt.subplot(142)\n",
        "plt.imshow(X_train[4], interpolation=\"bicubic\")\n",
        "plt.grid(False)\n",
        "plt.subplot(143)\n",
        "plt.imshow(X_train[8], interpolation=\"bicubic\")\n",
        "plt.grid(False)\n",
        "plt.subplot(144)\n",
        "plt.imshow(X_train[12], interpolation=\"bicubic\")\n",
        "plt.grid(False)\n",
        "plt.show()\n",
        "\n",
        "# 이미지 정규화 ( 스케일링 )\n",
        "print (\"mean before normalization:\", np.mean(X_train)) \n",
        "print (\"std before normalization:\", np.std(X_train))\n",
        "\n",
        "mean=[0,0,0]\n",
        "std=[0,0,0]\n",
        "newX_train = np.ones(X_train.shape)\n",
        "newX_test = np.ones(X_test.shape)\n",
        "for i in range(3):\n",
        "    mean[i] = np.mean(X_train[:,:,:,i])\n",
        "    std[i] = np.std(X_train[:,:,:,i])\n",
        "    \n",
        "for i in range(3):\n",
        "    newX_train[:,:,:,i] = X_train[:,:,:,i] - mean[i]\n",
        "    newX_train[:,:,:,i] = newX_train[:,:,:,i] / std[i]\n",
        "    newX_test[:,:,:,i] = X_test[:,:,:,i] - mean[i]\n",
        "    newX_test[:,:,:,i] = newX_test[:,:,:,i] / std[i]\n",
        "        \n",
        "    \n",
        "X_train = newX_train\n",
        "X_test = newX_test\n",
        "\n",
        "print (\"mean after normalization:\", np.mean(X_train))\n",
        "print (\"std after normalization:\", np.std(X_train))\n",
        "print(X_train.max())\n",
        "\n",
        "# 모델 구현 및 훈련 - 재구현 필요\n",
        "num_classes = 10     \n",
        "batchSize = 512                   #-- Training Batch Size\n",
        "num_epochs = 20                   #-- Number of epochs for training   \n",
        "learningRate= 0.01                #-- Learning rate for the network\n",
        "img_rows = 32                     #-- input image dimensions\n",
        "img_cols = 32 \n",
        "img_ch=3\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Conv2D(64, (3, 3), activation='relu', padding='same', input_shape=(img_rows, img_cols, img_ch)))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Conv2D(64, (3, 3), activation='relu', padding='same'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Conv2D(128, (3, 3), activation='relu', padding='same'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Conv2D(256, (3, 3), activation='relu', padding='same'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(512, activation='relu'))\n",
        "model.add(Dense(512, activation='relu'))\n",
        "model.add(Dense(num_classes, activation='softmax'))\n",
        "model.compile(loss='sparse_categorical_crossentropy', optimizer='adam',  metrics=['accuracy'])\n",
        "\n",
        "print(X_train.shape)\n",
        "print(y_train.shape)\n",
        "\n",
        "model.fit(X_train, y_train, batch_size=batchSize, epochs=num_epochs)\n",
        "\n",
        "# 모델 평가\n",
        "result = model.evaluate(X_test, y_test)\n",
        "print(result)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}